{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79728c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some potentially useful modules\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "class NeuralMMAgent(object):\n",
    "    '''\n",
    "    Class to for Neural Net Agents that compete in the Mob task\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_in_nodes, num_hid_nodes, num_hid_layers, num_out_nodes, \\\n",
    "                 learning_rate=0.2, max_epoch=10000, min_sse=.01, momentum=0, \\\n",
    "                 creation_function=None, activation_function=None, random_seed=1):\n",
    "        '''\n",
    "        Arguments:\n",
    "            num_in_nodes -- total # of input nodes for Neural Net\n",
    "            num_hid_nodes -- total # of hidden nodes for each hidden layer\n",
    "                in the Neural Net\n",
    "            num_hid_layers -- total # of hidden layers for Neural Net\n",
    "            num_out_nodes -- total # of output layers for Neural Net\n",
    "            learning_rate -- learning rate to be used when propogating error\n",
    "            max_epoch -- maximum number of epochs for our NN to run during learning\n",
    "            min_sse -- minimum SSE that we will use as a stopping point\n",
    "            momentum -- Momentum term used for learning\n",
    "            creation_function -- function that will be used to create the\n",
    "                neural network given the input\n",
    "            activation_function -- list of two functions:\n",
    "                1st function will be used by network to determine activation given a weighted summed input\n",
    "                2nd function will be the derivative of the 1st function\n",
    "            random_seed -- used to seed object random attribute.\n",
    "                This ensures that we can reproduce results if wanted\n",
    "        '''\n",
    "        self.num_in_nodes = num_in_nodes\n",
    "        self.num_hid_nodes = num_hid_nodes\n",
    "        self.num_hid_layers = num_hid_layers\n",
    "        self.num_out_nodes = num_out_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epoch = max_epoch\n",
    "        self.min_sse = min_sse\n",
    "        self.momentum = momentum\n",
    "        self.creation_function = creation_function\n",
    "        self.activation_function = activation_function\n",
    "        self.random_seed = random_seed\n",
    "        self.layer_nodes = []\n",
    "        self.layer_nodes.append(self.num_in_nodes)\n",
    "        for i in range(self.num_hid_layers):\n",
    "            self.layer_nodes.append(self.num_hid_nodes)\n",
    "        self.layer_nodes.append(self.num_out_nodes)\n",
    "        random.seed(self.random_seed)\n",
    "        self.num_weights = [4, 2]\n",
    "\n",
    "        assert num_in_nodes > 0 and num_hid_layers > 0 and num_hid_nodes and \\\n",
    "               num_out_nodes > 0, \"Illegal number of input, hidden, or output layers!\"\n",
    "\n",
    "    def train_net_incremental(self, input_list, output_list, max_num_epoch=100000, min_sse=0.001):\n",
    "        ''' Trains neural net using incremental learning\n",
    "            (update once per input-output pair)\n",
    "            Arguments:\n",
    "                input_list -- 2D list of inputs\n",
    "                output_list -- 2D list of outputs matching inputs\n",
    "            Outputs:\n",
    "                1d list of errors (total error each epoch) (e.g., [0.1])\n",
    "        '''\n",
    "        # Some code...#\n",
    "        # all_err.append(total_err)\n",
    "\n",
    "        # if (total_err < min_sse):\n",
    "        # break\n",
    "        all_err = []\n",
    "        errors = 0\n",
    "        for epoch in range(max_num_epoch):\n",
    "            total_err = 0\n",
    "            for row in range(len(input_list)):\n",
    "                activations = self._feed_forward(input_list, row)\n",
    "                # errors.append([output_list[row][0] - activations[-1][0]])\n",
    "                # self._adjust_weights_bias(activations, error)\n",
    "                errors = output_list[row][0] - activations[-1][0]\n",
    "                result_deltas = self._calculate_deltas(activations, errors, prev_weight_deltas=None)\n",
    "                self._adjust_weights_bias(result_deltas[1])\n",
    "                total_err += output_list[row][0] - activations[-1][0]\n",
    "\n",
    "            all_err.append(total_err)\n",
    "            if total_err < min_sse:\n",
    "                break\n",
    "        return all_err\n",
    "\n",
    "    def _feed_forward(self, input_list, row):\n",
    "        '''Used to feedforward input and calculate all activation values\n",
    "            Arguments:\n",
    "                input_list -- a list of possible input values\n",
    "                row -- the row from that input_list that we should use\n",
    "            Outputs:\n",
    "                list of activation values\n",
    "        '''\n",
    "        \n",
    "        activations = []\n",
    "        weight_multiply = []\n",
    "        hid_activation = []\n",
    "        output = 0\n",
    "\n",
    "        # Input layer activations\n",
    "        activations.append(input_list[row])\n",
    "\n",
    "        # Hidden layer activations\n",
    "        start = 0\n",
    "        end = self.num_hid_nodes\n",
    "        for i in activations[0]:\n",
    "            for j in range(start, end):\n",
    "                weight_multiply.append(i * self.weights[0][j])\n",
    "            start = end\n",
    "            end = end + self.num_hid_nodes\n",
    "        for j in range(self.num_hid_nodes):\n",
    "            sum_wx = sum([activations[i][0] * self.weights[i + 1][j] for i in range(self.num_hid_layers)])\n",
    "            hid_activation.append(sum_wx)\n",
    "        activations.append(hid_activation)\n",
    "\n",
    "        # Output layer activation\n",
    "        for i in range(self.num_out_nodes):\n",
    "            sum_wx = sum(\n",
    "                [hid_activation[j] * self.weights[-1][j * self.num_out_nodes + i] for j in range(self.num_hid_nodes)])\n",
    "            output += sum_wx\n",
    "        activations.append([output])\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def _calculate_deltas(self, activations, errors, prev_weight_deltas=None):\n",
    "        '''Used to calculate all weight deltas for our neural net\n",
    "            Parameters:\n",
    "                activations -- a 2d list of activation values\n",
    "                errors -- a 2d list of errors\n",
    "                prev_weight_deltas [OPTIONAL] -- a 2d list of previous weight deltas\n",
    "            Output:\n",
    "                A tuple made up of 3 items:\n",
    "                    A 2d list of little deltas (e.g., [[0, 0], [-0.1, 0.1], [0.1]])\n",
    "                    A 2d list of weight deltas (e.g., [[-0.1, 0.1, -0.1, 0.1], [0.1, 0.1]])\n",
    "                    A 2d list of bias deltas (e.g., [[0, 0], [-0.1, 0.1], [0]])\n",
    "        '''\n",
    "\n",
    "        # Calculate error gradient for each output node & propgate error\n",
    "        #   (calculate weight deltas going backward from output_nodes)\n",
    "        little_deltas = []\n",
    "        little_deltas.append([0] * self.num_in_nodes)\n",
    "        little_deltas.append([0] * self.num_hid_nodes)\n",
    "        little_deltas.append([0] * self.num_out_nodes)\n",
    "        error_gradient = 0\n",
    "\n",
    "        # output layer\n",
    "        for i in range(self.num_out_nodes):\n",
    "            error_gradient = errors * self.sigmoid_af_deriv(activations[-1][i])\n",
    "            little_deltas[-1][i] = error_gradient\n",
    "\n",
    "        # hidden-layer to output layer\n",
    "        error_gradient = 0\n",
    "        for j in range(self.num_hid_nodes):\n",
    "            error_gradient += little_deltas[-1][0] * self.weights[-1][j]\n",
    "            error_gradient *= self.sigmoid_af_deriv(activations[-1][0])\n",
    "            little_deltas[-2][j] = error_gradient\n",
    "\n",
    "        # middle hidden layer\n",
    "        start = 0\n",
    "        end = self.num_hid_nodes\n",
    "        if self.num_hid_layers == 1:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(self.num_hid_layers, -1, -1):\n",
    "                for j in range(self.num_hid_nodes):\n",
    "                    error_gradient = 0\n",
    "                    for t in range(self.num_hid_layers, -1, -1):\n",
    "                        for k in range(start, end):\n",
    "                            error_gradient += little_deltas[i][j] * self.weights[t][k]\n",
    "                        start = self.num_hid_nodes\n",
    "                        end = start + self.num_hid_nodes\n",
    "                        error_gradient *= self.sigmoid_af_deriv(activations[i][j])\n",
    "                        little_deltas[i - 1][j] = error_gradient\n",
    "\n",
    "        for i in range(self.num_in_nodes):\n",
    "            little_deltas[0][i] = 0\n",
    "\n",
    "        weight_deltas = []\n",
    "        for i in range(self.num_hid_layers):\n",
    "            weight_deltas.append(np.zeros((self.num_hid_nodes * self.num_hid_nodes, 1)))\n",
    "        weight_deltas.append(np.zeros((self.num_hid_nodes * self.num_out_nodes, 1)))\n",
    "\n",
    "        start_w = 0\n",
    "        end_w = self.num_hid_nodes\n",
    "        for i in range(self.num_hid_layers):\n",
    "            for j in range(self.num_hid_nodes):\n",
    "                for k in range(start_w,end_w):\n",
    "                    weight_deltas[i][k] = self.learning_rate * little_deltas[i+1][j] * activations[i+1][j]\n",
    "                start_w = self.num_hid_nodes\n",
    "                end_w = start_w + self.num_hid_nodes\n",
    "\n",
    "        for i in range(self.num_hid_nodes * self.num_out_nodes):\n",
    "            weight_deltas[-1][i] = self.learning_rate * little_deltas[-1][0] * activations[-1][0]\n",
    "\n",
    "\n",
    "        \"\"\"           \n",
    "        bias_deltas = []\n",
    "        for i in range(self.num_hid_layers):\n",
    "            bias_deltas.append([0]*self.layer_nodes[i])\n",
    "\n",
    "        for i in range(self.num_layers-1):\n",
    "            for j in range(self.layer_nodes[i+1]):\n",
    "                bias_deltas[i+1][j] = self.learning_rate * little_deltas[i+1][j] + \\\n",
    "                                            self.momentum * self.previous_bias_deltas[i+1][j]\n",
    "        \"\"\"\n",
    "        return (little_deltas, weight_deltas)\n",
    "\n",
    "    def _adjust_weights_bias(self, weight_deltas):\n",
    "        '''Used to apply deltas\n",
    "        Parameters:\n",
    "            weight_deltas -- 2d list of weight deltas\n",
    "            bias_deltas -- 2d list of bias deltas\n",
    "        Outputs:\n",
    "            A tuple w/ the following items (in order):\n",
    "            2d list of all weights after updating (e.g. [[-0.071, 0.078, 0.313, 0.323], [-0.34, 0.021]])\n",
    "            list of all biases after updating (e.g., [[0, 0], [0, 0], [0]])\n",
    "        '''\n",
    "        for i in range(self.num_hid_layers + 1):\n",
    "            for j in range(self.num_weights[i]):\n",
    "                self.weights[i][j] -= weight_deltas[i][j]\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers):\n",
    "            self.bias[i] -= self.bias_deltas[i]\n",
    "        \"\"\"\n",
    "        # self.previous_weight_deltas = weight_deltas\n",
    "        # self.previous_bias_deltas = self.bias_deltas\n",
    "\n",
    "        return self.weights\n",
    "\n",
    "    #########ACCESSORS\n",
    "\n",
    "    def get_weights(self):\n",
    "        return (self.weights)\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights\n",
    "\n",
    "    def get_bias(self):\n",
    "        return (self.bias)\n",
    "\n",
    "    def set_biases(self, bias):\n",
    "        self.bias = bias\n",
    "\n",
    "    ################\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_af(summed_input):\n",
    "        # Sigmoid function\n",
    "        return 1 / (1 + np.exp(-summed_input))\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_af_deriv(sig_output):\n",
    "        # the derivative of the sigmoid function\n",
    "        return sig_output * (1 - sig_output)\n",
    "        pass\n",
    "\n",
    "\n",
    "# ----#\n",
    "# Some quick test code\n",
    "\n",
    "test_agent = NeuralMMAgent(2, 2, 1, 1, random_seed=5, max_epoch=1000000, learning_rate=0.2, momentum=0)\n",
    "test_in = [[1, 0], [0, 0], [1, 1], [0, 1]]\n",
    "test_out = [[1], [0], [0], [1]]\n",
    "test_agent.set_weights([[-.37, .26, .1, -.24], [-.01, -.05]])\n",
    "test_agent.set_biases([[0, 0], [0, 0], [0]])\n",
    "all_errors = test_agent.train_net_incremental(test_in, test_out, min_sse=test_agent.min_sse,\n",
    "                                              max_num_epoch=test_agent.max_epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13102496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0271711954963474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fc96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
